"""
YouTube Watch History Analysis

This script processes YouTube watch history HTML files to extract:
- Video IDs
- Timestamps
- Video Categories

It then creates insightful visualizations:
- Number of videos by category
- Category distribution
- Daily trends of videos watched
- Hourly viewing heatmap
- Total time spent by category

Author: Your Name
"""

import re
from bs4 import BeautifulSoup
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from googleapiclient.discovery import build
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Replace with your API Key
API_KEY = "YOUR_YOUTUBE_API_KEY"  # Add your YouTube API Key here
youtube = build("youtube", "v3", developerKey=API_KEY)

# YouTube Category Mapping
category_map = {
    "1": "Film & Animation",
    "2": "Autos & Vehicles",
    "10": "Music",
    "15": "Pets & Animals",
    "17": "Sports",
    "19": "Travel & Events",
    "20": "Gaming",
    "22": "People & Blogs",
    "23": "Comedy",
    "24": "Entertainment",
    "25": "News & Politics",
    "26": "Howto & Style",
    "27": "Education",
    "28": "Science & Technology",
    "29": "Nonprofits & Activism"
}

def extract_video_ids_and_timestamps(file_path, chunk_size=1000):
    """
    Extract video IDs and timestamps from an HTML file in chunks for better performance.
    """
    video_data = []
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = []
        for i, line in enumerate(file):
            lines.append(line)
            if i > 0 and i % chunk_size == 0:
                soup = BeautifulSoup("".join(lines), 'lxml')  # Parse the chunk
                for item in soup.find_all('a', href=True):
                    if "watch?v=" in item['href']:
                        video_id = re.search(r"v=([a-zA-Z0-9_-]+)", item['href'])
                        timestamp_tag = item.find_next('time')  # Extract timestamp
                        if video_id and timestamp_tag:
                            video_data.append({
                                "video_id": video_id.group(1),
                                "timestamp": timestamp_tag.text.strip()
                            })
                lines = []  # Clear the processed chunk
                print(f"Processed {i} lines...")
        # Process remaining lines
        if lines:
            soup = BeautifulSoup("".join(lines), 'lxml')
            for item in soup.find_all('a', href=True):
                if "watch?v=" in item['href']:
                    video_id = re.search(r"v=([a-zA-Z0-9_-]+)", item['href'])
                    timestamp_tag = item.find_next('time')
                    if video_id and timestamp_tag:
                        video_data.append({
                            "video_id": video_id.group(1),
                            "timestamp": timestamp_tag.text.strip()
                        })
    return video_data

def fetch_categories_with_timestamps(video_data):
    """
    Fetch categories from YouTube API and include timestamps.
    """
    categories = []
    video_ids = [item['video_id'] for item in video_data]
    timestamps = {item['video_id']: item['timestamp'] for item in video_data}

    for i in range(0, len(video_ids), 50):  # Process in batches of 50
        batch = video_ids[i:i+50]
        request = youtube.videos().list(
            part="snippet",
            id=",".join(batch)
        )
        response = request.execute()
        for item in response.get('items', []):
            video_title = item['snippet']['title']
            category_id = item['snippet']['categoryId']
            category_name = category_map.get(category_id, "Unknown")
            video_id = item['id']
            categories.append({
                "video_id": video_id,
                "timestamp": timestamps.get(video_id, "Unknown"),  # Add timestamp
                "title": video_title,
                "category_id": category_id,
                "category_name": category_name
            })
    return categories

def save_to_csv(data, output_file):
    """
    Save the extracted data to a CSV file.
    """
    df = pd.DataFrame(data)
    df.to_csv(output_file, index=False)
    print(f"Data saved to {output_file}")

def visualize_data(file_path):
    """
    Load and visualize YouTube data.
    """
    # Step 1: Load the data
    df = pd.read_csv(file_path)

    # Convert 'timestamp' to datetime for time-based analysis
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df['date'] = df['timestamp'].dt.date  # Extract date
    df['hour'] = df['timestamp'].dt.hour  # Extract hour of the day

    # Step 2: Bar Chart - Number of Videos Watched by Category
    plt.figure(figsize=(12, 6))
    category_counts = df['category_name'].value_counts()
    category_counts.plot(kind='bar', title='Number of Videos Watched by Category')
    plt.xlabel('Category')
    plt.ylabel('Number of Videos')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Step 3: Pie Chart - Category Distribution
    plt.figure(figsize=(8, 8))
    category_counts.plot(kind='pie', autopct='%1.1f%%', title='Category Distribution', legend=True)
    plt.ylabel('')
    plt.tight_layout()
    plt.show()

    # Step 4: Line Chart - Daily Viewing Trends by Category
    category_trends = df.groupby(['date', 'category_name']).size().unstack(fill_value=0)
    category_trends.plot(figsize=(15, 8), title='Daily Viewing Trends by Category')
    plt.xlabel('Date')
    plt.ylabel('Number of Videos Watched')
    plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.show()

    # Step 5: Heatmap - Hourly Viewing Trends by Category
    hourly_trends = df.groupby(['hour', 'category_name']).size().unstack(fill_value=0)
    plt.figure(figsize=(15, 8))
    sns.heatmap(hourly_trends, cmap='coolwarm', cbar=True)
    plt.title('Hourly Viewing Trends by Category')
    plt.xlabel('Hour of the Day')
    plt.ylabel('Category')
    plt.tight_layout()
    plt.show()

    # Step 6: Stacked Bar Chart - Total Time Spent by Category
    df['time_spent_minutes'] = 10  # Assume 10 minutes per video
    time_spent_by_category = df.groupby('category_name')['time_spent_minutes'].sum()
    time_spent_by_category.plot(kind='bar', figsize=(12, 6), title='Total Time Spent by Category')
    plt.xlabel('Category')
    plt.ylabel('Time Spent (Minutes)')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Main Workflow
if __name__ == "__main__":
    # Extract data
    html_file_path = '/content/drive/MyDrive/YouTube_Project/watch-history.html'
    output_csv = '/content/drive/MyDrive/YouTube_Project/watch_timestamps_and_categories.csv'

    print("Processing the HTML file...")
    video_data = extract_video_ids_and_timestamps(html_file_path)
    print(f"Extracted {len(video_data)} entries with timestamps.")

    print("Fetching categories using YouTube API...")
    categories = fetch_categories_with_timestamps(video_data)

    save_to_csv(categories, output_csv)

    # Visualize data
    visualize_data(output_csv)
